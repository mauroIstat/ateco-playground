{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f1bdb1c",
   "metadata": {},
   "source": [
    "# CIRCE vs Semantic Search - ATECO 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "from typing import List\n",
    "from semantic_search.data import build_corpus\n",
    "from semantic_search.local import LocalKnowledgeBase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb20534f",
   "metadata": {},
   "source": [
    "## Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592a134c",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTRACT_CIRCE : bool = False\n",
    "CIRCE_URL     : str  = \"https://www.istat.it/wp-content/themes/EGPbs5-child/ateco/atecor.php\"\n",
    "CIRCE_FILENAME: str  = \"data/circe_results.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaa9833",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0eaa11",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac5511f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ateco_df = pd.read_csv(\"data/ateco_2022_raw.csv\")\n",
    "ateco_df = ateco_df[ateco_df[\"section\"].str.len() == 8]\n",
    "\n",
    "codes = []\n",
    "texts = []\n",
    "for i, row in ateco_df.iterrows():\n",
    "    if row[\"title\"]:\n",
    "        codes.append(row[\"section\"])\n",
    "        texts.append(row[\"title\"].lower())\n",
    "\n",
    "    if type(row[\"description\"]) == str:\n",
    "        desc = row[\"description\"]\n",
    "        desc = desc.split(\". Sono escluse\")[0]\n",
    "        desc_list = desc.split(\" - \")\n",
    "        for d in desc_list:\n",
    "            codes.append(row[\"section\"])\n",
    "            texts.append(d.lower().strip(\"- \"))\n",
    "\n",
    "sample_queries_df = pd.read_csv(\"data/ateco_sample_queries.csv\", sep=\";\")\n",
    "sampled_df = sample_queries_df.sample(1000, random_state=42)\n",
    "sampled_df.drop(columns=[\"ID\"], inplace=True)\n",
    "sampled_df.rename(columns={\"Stringa\": \"query\"}, inplace=True)\n",
    "\n",
    "queries = sampled_df[\"query\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import CIRCE labeled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd94c441",
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXTRACT_CIRCE:\n",
    "    headers = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n",
    "\n",
    "    with open(CIRCE_FILENAME, \"w\") as f:\n",
    "        json.dump({}, f)\n",
    "\n",
    "    results_dict = {}\n",
    "    for idx, query in enumerate(queries):\n",
    "        results_dict[idx] = {}\n",
    "        results_dict[idx][\"query\"] = query\n",
    "        data = {\"search\": query}\n",
    "        try:\n",
    "            response = requests.post(CIRCE_URL, data=data, headers=headers)\n",
    "            response_dict = ast.literal_eval(response.text.replace('\"\"', '\"'))\n",
    "\n",
    "            results_dict[idx][\"result\"] = {}\n",
    "\n",
    "            for j, res in enumerate(response_dict[\"0\"]):\n",
    "                results_dict[idx][\"result\"][j] = {}\n",
    "                code = res[\"ateco_code\"]\n",
    "                desc = res[\"ateco_description\"]\n",
    "                results_dict[idx][\"result\"][j][\"code\"] = code\n",
    "                results_dict[idx][\"result\"][j][\"desc\"] = desc\n",
    "\n",
    "        except:\n",
    "            results_dict[idx][\"result\"] = \"ERROR\"\n",
    "\n",
    "        with open(CIRCE_FILENAME, \"r\") as f:\n",
    "            json_data = json.load(f)\n",
    "        json_data.update(results_dict)\n",
    "        with open(CIRCE_FILENAME, \"w\") as f:\n",
    "            json.dump(json_data, f)\n",
    "\n",
    "        time.sleep(0.005)\n",
    "\n",
    "else:\n",
    "    with open(CIRCE_FILENAME, \"r\") as f:\n",
    "        results_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f06d2f7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c4ee23",
   "metadata": {},
   "source": [
    "## Semantic Search\n",
    "First, we create the knowledge base for the ATECO 2022 classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a44cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = build_corpus(\n",
    "    texts=texts,\n",
    "    ids=list(range(len(texts))),\n",
    "    metadata=[{\"code\": c} for c in codes]\n",
    ")\n",
    "base = LocalKnowledgeBase(\n",
    "    corpus=corpus,\n",
    "    model_id=\"BAAI/bge-m3\",\n",
    "    batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4734ddc",
   "metadata": {},
   "source": [
    "Then, we search the knowledge base and extract the matching between CIRCE and semantic search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e21abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_top_k = 10\n",
    "\n",
    "results = base.search(queries, top_k=30)\n",
    "\n",
    "def parse_retrieved(results):\n",
    "    codes = [r.metadata[\"code\"] for r in results]\n",
    "    texts = [r.text for r in results]\n",
    "    scores = [r.score for r in results]\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"code\": codes,\n",
    "        \"matched_text\": texts,\n",
    "        \"score\": scores\n",
    "    })\n",
    "\n",
    "    grouped_df = df.groupby(\"code\").aggregate({\n",
    "        \"score\": \"max\",\n",
    "    }).reset_index()\n",
    "\n",
    "    return grouped_df.sort_values(\"score\", ascending=False)\n",
    "\n",
    "top_results = []\n",
    "circe_guess = []\n",
    "sem_search_guess = []\n",
    "\n",
    "for idx, res in enumerate(results):\n",
    "    circe = results_dict[str(idx)][\"result\"]\n",
    "    if circe == \"ERROR\":\n",
    "        continue\n",
    "    ateco_circe = set(np.unique([circe[key][\"code\"] for key in circe.keys()]).tolist())\n",
    "\n",
    "    sem_search_res = parse_retrieved(res.results).iloc[:match_top_k][\"code\"].tolist()\n",
    "    sem_search_res = set([r[:-1] for r in sem_search_res])\n",
    "\n",
    "    if ateco_circe.intersection(sem_search_res):\n",
    "        top_results.append(1)\n",
    "    else:\n",
    "        top_results.append(0)\n",
    "\n",
    "    circe_guess.append(list(ateco_circe))\n",
    "    sem_search_guess.append(list(sem_search_res))\n",
    "\n",
    "print(f\"Overlap (Top {match_top_k})): {round(np.mean(top_results)*100, 2)}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
